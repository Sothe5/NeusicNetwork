{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_biases(number_of_neurons):\n",
    "    biases = {}\n",
    "    for i in range(len(number_of_neurons)):\n",
    "        biases[\"b{}\".format(i)] = tf.Variable(tf.random_normal([number_of_neurons[i]]))\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights(number_of_neurons, n_inputs):\n",
    "    weights = {}\n",
    "    weights[\"w0\"] = tf.Variable(tf.random_normal([n_inputs,number_of_neurons[0]]))\n",
    "    for i in range(1,len(number_of_neurons)):\n",
    "        weights[\"w{}\".format(i)] = tf.Variable(tf.random_normal([number_of_neurons[i-1],number_of_neurons[i]]))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : placeholder for the data\n",
    "    weights : Dictionary\n",
    "    biases : Dictionary\n",
    "    '''\n",
    "    progression = []\n",
    "    activation = []\n",
    "    for i in range(len(number_of_neurons)):\n",
    "        progression.append(tf.add(tf.matmul(x, weights[\"w{}\".format(i)]), biases[\"b{}\".format(i)]))\n",
    "        activation.append(tf.nn.tanh(progression[i]))\n",
    "    \n",
    "    return activation[len(number_of_neurons)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float32')\n",
    "y = tf.placeholder('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 19\n",
    "number_of_neurons = [256, 256, 256,256, 256, 256,256, 256, 256,256, 256, 256]\n",
    "biases = create_biases(number_of_neurons)\n",
    "weights = create_weights(number_of_neurons, n_inputs)\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "n_classes = 10\n",
    "n_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-173-658afba1c53e>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-173-658afba1c53e>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    _,c = sess.run([optimizer,cost], feed_dict={x=range(19),y=[0,0,0,0,1,0,0,0,0,0]})\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batches = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batches):\n",
    "        \n",
    "        _,c = sess.run([optimizer,cost], feed_dict={x=range(19),y=[0,0,0,0,1,0,0,0,0,0]})\n",
    "        \n",
    "        avg_cost = c/total_batches;\n",
    "        \n",
    "    print(\"Epoch: {} cost= {}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Finished with {} epochs with cost {}\".formta(training_epochs,avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

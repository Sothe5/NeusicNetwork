{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize random biases\n",
    "def create_biases(number_of_neurons, n_classes):\n",
    "    biases = []\n",
    "    #Hidden layers\n",
    "    for i in range(len(number_of_neurons)):\n",
    "        biases.append(tf.Variable(tf.random_normal([number_of_neurons[i]])))\n",
    "    #Output Layer\n",
    "    biases.append(tf.Variable(tf.random_normal([n_classes])))\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize random weights\n",
    "def create_weights(number_of_neurons, n_inputs, n_classes):\n",
    "    weights = []\n",
    "    #First layer (nºinputs x nºneurons)\n",
    "    weights.append(tf.Variable(tf.random_normal([n_inputs,number_of_neurons[0]])))\n",
    "    \n",
    "    #Hidden layers\n",
    "    for i in range(1,len(number_of_neurons)):\n",
    "        weights.append(tf.Variable(tf.random_normal([number_of_neurons[i-1],number_of_neurons[i]])))\n",
    "    #Output layer (nºneuros x nºoutputs)\n",
    "    weights.append(tf.Variable(tf.random_normal([number_of_neurons[len(number_of_neurons)-1],\n",
    "                                                                                  n_classes])))    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    progression = []\n",
    "    activation = []\n",
    "    progression.append(tf.add(tf.matmul(x, weights[0]), biases[0]))\n",
    "    activation.append(tf.nn.tanh(progression[0]))\n",
    "    for i in range(1, len(number_of_neurons)+1):\n",
    "        progression.append(tf.add(tf.matmul(activation[i-1], weights[i]), biases[i]))\n",
    "        activation.append(tf.nn.tanh(progression[i]))\n",
    "    \n",
    "    return activation[len(number_of_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDataFrom(path):\n",
    "    data = []\n",
    "    with open(path, 'rb') as f:\n",
    "        content = f.read()\n",
    "        data = pickle.loads(content)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "training_epochs = 1500\n",
    "n_samples = 1500 # Number of samples we have\n",
    "n_inputs = 13*5    #We get a matrix (13 x 5) when calculating the MFCC\n",
    "n_classes = 10     #Rock, blues, jazz...\n",
    "batch_size = int(n_samples/10) #Make a 10-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "unpickling stack underflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-56f7610b0f50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetDataFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-e2d453c670f8>\u001b[0m in \u001b[0;36mgetDataFrom\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: unpickling stack underflow"
     ]
    }
   ],
   "source": [
    "getDataFrom('sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input and correct output\n",
    "x = tf.constant(getDataFrom('inputs'))\n",
    "y = tf.constant(getDataFrom('labels'))\n",
    "\n",
    "#Create our Neural Network\n",
    "number_of_neurons = [256, 256, 256, 256]\n",
    "biases = create_biases(number_of_neurons, n_classes)\n",
    "weights = create_weights(number_of_neurons, n_inputs, n_classes)\n",
    "#Get predictions\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set cost and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inizialize variables for TensorFlow\n",
    "init = tf.global_variables_initializer()\n",
    "#Start session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRandomData():\n",
    "    in_x = np.random.randn(n_samples, n_inputs)\n",
    "    in_y = np.zeros((n_samples, n_classes))\n",
    "    for i in range(n_samples):\n",
    "        in_y[i][randint(0, n_classes-1)] = 1\n",
    "    return in_x, in_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_x, in_y = getRandomData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def taking_batches(input_x, expected_y, batch_size, offset):\n",
    "    return input_x[offset:offset+batch_size],expected_y[offset:offset+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500 cost= 2.1635\n",
      "Finished with 1500 epochs with cost 2.163471031188965\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "    total_batches = int(n_samples/batch_size)\n",
    "    for i in range(total_batches): \n",
    "        batch_x,batch_y = taking_batches(in_x,in_y,batch_size,i)\n",
    "        _,c = sess.run([optimizer,cost], feed_dict={x:batch_x,y:batch_y}) \n",
    "        avg_cost += c/total_batches;\n",
    "    clear_output()\n",
    "    print(\"Epoch: {} cost= {:.4f}\".format(epoch+1,avg_cost))\n",
    "    \n",
    "print(\"Finished with {} epochs with cost {}\".format(training_epochs,avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.11733333021402359\n"
     ]
    }
   ],
   "source": [
    "# Test error\n",
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "correct_predictions = tf.cast(correct_predictions, \"float\")\n",
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy.eval({x:in_x,y:in_y})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

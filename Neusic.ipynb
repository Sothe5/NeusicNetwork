{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa as lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize random biases\n",
    "def create_biases(number_of_neurons, n_classes):\n",
    "    biases = []\n",
    "    #Hidden layers\n",
    "    for i in range(len(number_of_neurons)):\n",
    "        biases.append(tf.Variable(tf.random_normal([number_of_neurons[i]])))\n",
    "    #Output Layer\n",
    "    biases.append(tf.Variable(tf.random_normal([n_classes])))\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize random weights\n",
    "def create_weights(number_of_neurons, n_inputs, n_classes):\n",
    "    weights = []\n",
    "    #First layer (nºinputs x nºneurons)\n",
    "    weights.append(tf.Variable(tf.random_normal([n_inputs,number_of_neurons[0]])))\n",
    "    \n",
    "    #Hidden layers\n",
    "    for i in range(1,len(number_of_neurons)):\n",
    "        weights.append(tf.Variable(tf.random_normal([number_of_neurons[i-1],number_of_neurons[i]])))\n",
    "    #Output layer (nºneuros x nºoutputs)\n",
    "    weights.append(tf.Variable(tf.random_normal([number_of_neurons[len(number_of_neurons)-1],\n",
    "                                                                                  n_classes])))    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    progression = []\n",
    "    activation = []\n",
    "    progression.append(tf.add(tf.matmul(x, weights[\"w0\"]), biases[\"b0\"]))\n",
    "    activation.append(tf.nn.tanh(progression[0]))\n",
    "    for i in range(1, len(number_of_neurons)):\n",
    "        progression.append(tf.add(tf.matmul(activation[i-1], weights[i]), biases[i]))\n",
    "        activation.append(tf.nn.tanh(progression[i]))\n",
    "    \n",
    "    progression.append(tf.add(tf.matmul(activation[len(number_of_neurons)-1],\n",
    "                                        weights[len(number_of_neurons)]), biases[len(number_of_neurons)]))\n",
    "    activation.append(tf.nn.tanh(progression[len(number_of_neurons)]))\n",
    "    \n",
    "    return activation[len(number_of_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "training_epochs = 1500\n",
    "batch_size = 1\n",
    "n_inputs = 13*5    #We get a matrix (13 x 5) when calculating the MFCC\n",
    "n_classes = 10     #Rock, blues, jazz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input and correct output\n",
    "x = tf.placeholder(\"float\", [None, n_inputs])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "#Create our Neural Network\n",
    "number_of_neurons = [256, 256, 256,256, 256, 256,256, 256, 256,256, 256, 256]\n",
    "biases = create_biases(number_of_neurons, n_classes)\n",
    "weights = create_weights(number_of_neurons, n_inputs, n_classes)\n",
    "#Get predictions\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "n_samples = 1500 # Number of samples we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set cost and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inizialize variables for TensorFlow\n",
    "init = tf.global_variables_initializer()\n",
    "#Start session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRandomData():\n",
    "    in_x = np.random.randn(n_samples, n_inputs)\n",
    "    in_y = np.zeros((n_samples, n_classes))\n",
    "    for i in range(n_samples):\n",
    "        matrix[i][randint(0, n_classes-1)] = 1\n",
    "    return in_x, in_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_x, in_y = getRandomData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def taking_batches(input_x, expected_y, batch_size, offset):\n",
    "    return input_x[offset:offset+batch_size],expected_y[offset:offset+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "    total_batches = int(n_samples/batch_size)\n",
    "    for i in range(total_batches): \n",
    "        batch_x,batch_y = taking_batches(in_x,in_y,batch_size,i)\n",
    "        _,c = sess.run([optimizer,cost], feed_dict={x:batch_x,y:batch_y}) \n",
    "        avg_cost += c/total_batches;\n",
    "        clear_output()\n",
    "        print(\"Epoch: {} cost= {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Finished with {} epochs with cost {}\".format(training_epochs,avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test error\n",
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "correct_predictions = tf.cast(correct_predictions, \"float\")\n",
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy.eval({x:in_x,y:matrix})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

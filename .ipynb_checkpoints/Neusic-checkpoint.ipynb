{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa as lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"C:\\\\Users\\\\Nexel\\\\Music\\\\q.mp3\")\n",
    "y, sr = lb.load(\"C:\\\\Users\\\\Nexel\\\\Music\\\\q.mp3\", duration=5.0)\n",
    "\n",
    "for \n",
    "lb.feature.mfcc(y=y, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_biases(number_of_neurons, n_classes):\n",
    "    biases = {}\n",
    "    for i in range(len(number_of_neurons)):\n",
    "        biases[\"b{}\".format(i)] = tf.Variable(tf.random_normal([number_of_neurons[i]]))\n",
    "    biases[\"b{}\".format(len(number_of_neurons))] = tf.Variable(tf.random_normal([n_classes]))\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_weights(number_of_neurons, n_inputs, n_classes):\n",
    "    weights = {}\n",
    "    weights[\"w0\"] = tf.Variable(tf.random_normal([n_inputs,number_of_neurons[0]]))\n",
    "    for i in range(1,len(number_of_neurons)):\n",
    "        weights[\"w{}\".format(i)] = tf.Variable(tf.random_normal([number_of_neurons[i-1],number_of_neurons[i]]))\n",
    "    weights[\"w{}\".format(len(number_of_neurons))] = tf.Variable(tf.random_normal([number_of_neurons[len(number_of_neurons)-1],\n",
    "                                                                                  n_classes]))    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : placeholder for the data\n",
    "    weights : Dictionary\n",
    "    biases : Dictionary\n",
    "    '''\n",
    "    progression = []\n",
    "    activation = []\n",
    "    progression.append(tf.add(tf.matmul(x, weights[\"w0\"]), biases[\"b0\"]))\n",
    "    activation.append(tf.nn.tanh(progression[0]))\n",
    "    for i in range(1, len(number_of_neurons)+1):\n",
    "        progression.append(tf.add(tf.matmul(activation[i-1], weights[\"w{}\".format(i)]), biases[\"b{}\".format(i)]))\n",
    "        activation.append(tf.nn.tanh(progression[i]))\n",
    "    \n",
    "    return activation[len(number_of_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 13*5 #The length of each array of the matrix\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_inputs])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_neurons = [256, 256, 256,256, 256, 256,256, 256, 256,256, 256, 256]\n",
    "biases = create_biases(number_of_neurons, n_classes)\n",
    "weights = create_weights(number_of_neurons, n_inputs, n_classes)\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "n_samples = 1500 # Number of samples we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2239628   0.88093884  0.15973255 ..., -0.10765875  0.41851941\n",
      "  -0.09559873]\n",
      " [ 0.51199687 -1.08468345  0.83460573 ...,  0.14763154 -0.184089\n",
      "  -0.18170683]\n",
      " [-1.74431341  0.7438802   0.0250001  ..., -0.53785965  0.32209171\n",
      "   0.78218011]\n",
      " ..., \n",
      " [ 0.4627976  -0.19393423  0.4040444  ...,  0.44049805 -0.52066601\n",
      "   0.69221022]\n",
      " [-0.17920703  1.92054229  0.39117972 ...,  0.69145773  0.02936589\n",
      "  -1.22205472]\n",
      " [-0.4371006   0.21011538  0.44961939 ...,  0.59356723 -0.79966469\n",
      "   0.78499935]]\n"
     ]
    }
   ],
   "source": [
    "in_x = np.random.randn(n_samples, n_inputs)\n",
    "print(in_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10)\n"
     ]
    }
   ],
   "source": [
    "#matrix = [[0 for x in range(n_classes)] for y in range(batch_size)] \n",
    "#for i in range(batch_size):\n",
    "#    matrix[np.random.randint(n_classes-1)][i] = 1\n",
    "    \n",
    "matrix = np.zeros((n_samples, n_classes))\n",
    "for i in range(n_samples):\n",
    "   matrix[i][randint(0, n_classes-1)] = 1\n",
    "\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taking_batches(input_x, expected_y, batch_size, offset):\n",
    "    return input_x[offset:offset+batch_size],expected_y[offset:offset+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost= 2.7086\n",
      "Epoch: 2 cost= 2.6811\n",
      "Epoch: 3 cost= 2.6724\n",
      "Epoch: 4 cost= 2.6602\n",
      "Epoch: 5 cost= 2.6480\n",
      "Epoch: 6 cost= 2.6254\n",
      "Epoch: 7 cost= 2.6676\n",
      "Epoch: 8 cost= 2.7054\n",
      "Epoch: 9 cost= 2.6700\n",
      "Epoch: 10 cost= 2.6678\n",
      "Epoch: 11 cost= 2.6665\n",
      "Epoch: 12 cost= 2.6037\n",
      "Epoch: 13 cost= 2.6365\n",
      "Epoch: 14 cost= 2.6160\n",
      "Epoch: 15 cost= 2.6519\n",
      "Epoch: 16 cost= 2.6394\n",
      "Epoch: 17 cost= 2.5910\n",
      "Epoch: 18 cost= 2.5869\n",
      "Epoch: 19 cost= 2.6064\n",
      "Epoch: 20 cost= 2.5555\n",
      "Epoch: 21 cost= 2.5542\n",
      "Epoch: 22 cost= 2.6070\n",
      "Epoch: 23 cost= 2.5878\n",
      "Epoch: 24 cost= 2.6527\n",
      "Epoch: 25 cost= 2.6317\n",
      "Epoch: 26 cost= 2.5994\n",
      "Epoch: 27 cost= 2.5962\n",
      "Epoch: 28 cost= 2.5465\n",
      "Epoch: 29 cost= 2.5011\n",
      "Epoch: 30 cost= 2.5851\n",
      "Epoch: 31 cost= 2.5758\n",
      "Epoch: 32 cost= 2.5481\n",
      "Epoch: 33 cost= 2.5672\n",
      "Epoch: 34 cost= 2.5333\n",
      "Epoch: 35 cost= 2.6015\n",
      "Epoch: 36 cost= 2.6160\n",
      "Epoch: 37 cost= 2.6384\n",
      "Epoch: 38 cost= 2.5434\n",
      "Epoch: 39 cost= 2.5538\n",
      "Epoch: 40 cost= 2.6473\n",
      "Epoch: 41 cost= 2.5792\n",
      "Epoch: 42 cost= 2.6060\n",
      "Epoch: 43 cost= 2.5355\n",
      "Epoch: 44 cost= 2.5167\n",
      "Epoch: 45 cost= 2.5793\n",
      "Epoch: 46 cost= 2.5101\n",
      "Epoch: 47 cost= 2.5096\n",
      "Epoch: 48 cost= 2.5362\n",
      "Epoch: 49 cost= 2.5868\n",
      "Epoch: 50 cost= 2.4750\n",
      "Finished with 50 epochs with cost 2.4749889373779297\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    total_batches = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batches):\n",
    "        \n",
    "        batch_x,batch_y = taking_batches(in_x,matrix,batch_size,i)\n",
    "        #print(batch_x)\n",
    "        \n",
    "        _,c = sess.run([optimizer,cost], feed_dict={x:batch_x,y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batches;\n",
    "        \n",
    "    print(\"Epoch: {} cost= {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Finished with {} epochs with cost {}\".format(training_epochs,avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test error\n",
    "correct_predictions = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10333333164453506\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(accuracy.eval({x:in_x,y:matrix})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
